{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: tokenizer in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (3.4.1)\r\n",
      "Requirement already satisfied: datasets in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (2.5.2)\r\n",
      "Requirement already satisfied: multiprocess in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.70.13)\r\n",
      "Requirement already satisfied: xxhash in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (3.0.0)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (2022.8.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.10.0)\r\n",
      "Requirement already satisfied: dill<0.3.6 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.3.5.1)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (4.64.1)\r\n",
      "Requirement already satisfied: aiohttp in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (3.8.3)\r\n",
      "Requirement already satisfied: pandas in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (1.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (1.23.3)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (9.0.0)\r\n",
      "Requirement already satisfied: responses<0.19 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: packaging in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (2.28.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (6.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.3.0)\r\n",
      "Requirement already satisfied: filelock in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.12)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from pandas->datasets) (2022.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n",
      "Fri Oct  7 13:15:16 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 43%   53C    P0   152W / 350W |    244MiB / 24576MiB |      5%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1643      G   /usr/lib/xorg/Xorg                106MiB |\r\n",
      "|    0   N/A  N/A      7605      G   /usr/bin/gnome-shell               51MiB |\r\n",
      "|    0   N/A  N/A      8935      G   ...on/Bin/AgentConnectix.bin        4MiB |\r\n",
      "|    0   N/A  N/A     10811      G   ...veSuggestionsOnlyOnDemand       52MiB |\r\n",
      "|    0   N/A  N/A   3085534      G   ...RendererForSitePerProcess       26MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! pip install tokenizer datasets\n",
    "! nvidia-smi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import torchdynamo\n",
    "import torch\n",
    "from typing import List\n",
    "from kernl.optimizer.dynamo_backend import dynamo_backend_ofi\n",
    "from kernl.implementations.cuda_graph import cuda_graphs_wrapper"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_name = \"BaptisteDoyen/camembert-base-xnli\"\n",
    "nli_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "nli_model = nli_model.eval().cuda()\n",
    "\n",
    "nli_model_opt = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "nli_model_opt = nli_model_opt.eval().cuda()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "torchdynamo.config.cache_size_limit = 256"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xnli (/home/geantvert/.cache/huggingface/datasets/xnli/fr/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6aa937c97524b1eafed9ca60d8eb408"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://huggingface.co/BaptisteDoyen/camembert-base-xnli\n",
    "dataset = load_dataset(\"xnli\", \"fr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# share cuda pool among all cuda graphs\n",
    "pool: (int, int) = torch.cuda.graph_pool_handle()\n",
    "\n",
    "\n",
    "def compiler(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor]):\n",
    "    dynamo_backend_ofi(gm)\n",
    "    return cuda_graphs_wrapper(gm, example_inputs, pool=pool)\n",
    "\n",
    "\n",
    "def run(*args, **kwargs):\n",
    "    with torchdynamo.optimize(compiler):\n",
    "        return nli_model_opt(*args, **kwargs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we do a warmup, it builds the triton kernels optimized for each size."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575s\n"
     ]
    }
   ],
   "source": [
    "# warmup\n",
    "start = time.time()\n",
    "shapes = [(1, w) for w in range(8, 128 + 8, 8)]\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast(enabled=True, dtype=torch.float16, cache_enabled=True):\n",
    "    for s in shapes:\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.ones(s, device=\"cuda\", dtype=torch.long),\n",
    "            \"attention_mask\": torch.ones(s, device=\"cuda\", dtype=torch.long),\n",
    "        }\n",
    "        _ = run(**inputs)\n",
    "        torch.cuda.synchronize()\n",
    "print(f\"{time.time() - start:.0f}s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete_time_baseline=43.80s\n",
      "complete_time_optimized=5.36s\n"
     ]
    }
   ],
   "source": [
    "complete_time_baseline = 0\n",
    "complete_time_optimized = 0\n",
    "\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast(enabled=True, dtype=torch.float16, cache_enabled=True):\n",
    "    for index, content in enumerate(dataset[\"test\"]):\n",
    "        premise, hypothesis, _ = content.values()\n",
    "        inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", pad_to_multiple_of=8, padding=True)\n",
    "        inputs = dict(inputs.to(\"cuda\"))\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        output_original = nli_model(**inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        complete_time_baseline += time.time() - start\n",
    "\n",
    "        start = time.time()\n",
    "        output_optimized = run(**inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        complete_time_optimized += time.time() - start\n",
    "        assert torch.allclose(\n",
    "            output_original.logits, output_optimized.logits, atol=1e-1\n",
    "        ), f\"logits don't match:\\n{output_original}\\n{output_optimized}\"\n",
    "\n",
    "print(f\"{complete_time_baseline=:.2f}s\")\n",
    "print(f\"{complete_time_optimized=:.2f}s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
