{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fused tiled matmul\n",
    "\n",
    "This is a follow-up of tiled `matmul` notebook.\n",
    "\n",
    "Fused `matmul` helps in reducing memory access and makes things faster as the intermediate outputs are never materialized (written in global memory).\n",
    "\n",
    "Introduction to the approach can be found there:\n",
    "https://github.com/NVIDIA/cutlass/tree/master/examples/13_two_tensor_op_fusion\n",
    "\n",
    "The main trick (and constrain) is to make one of the tile axis as big as one of the second matrix to multiply.\n",
    "Therefore, there will be no need to iterate over this axis. It won't work if the tile is too big for the `SRAM`.\n",
    "\n",
    "> In particular, if `Bx` is the right matrix in the second `matmul` operation, `n` axis matrix `bx` tiles length should be equal to `Nx` axis `Bx` matrix length (we follow the MKN axis names from GEMM).\n",
    "\n",
    "It introduces a constraint on the length of this axis which needs to be small enough to be kept in shared memory / registries.\n",
    "\n",
    "In the example below, we chain 2 `matmul`:\n",
    "\n",
    "* A1 = A0 @ B0\n",
    "* A2 = A1 @ B1\n",
    "\n",
    "> our goal is to never materialize A1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "M, N0, K0 = 15, 9, 12\n",
    "\n",
    "A0 = torch.rand((M, K0))\n",
    "B0 = torch.rand((K0, N0))\n",
    "\n",
    "# block_Nx is always equal to Nx\n",
    "# for simplification block tile shapes are all multiple of matrices shapes\n",
    "block_M, block_N0, block_K0 = M // 3, N0, K0 // 3\n",
    "\n",
    "# by definition K1 is always N0 as A1 is multiplied with B1 and A1 N axis is the one of B0\n",
    "N1, K1 = 12, N0\n",
    "\n",
    "# we iterate over N0 so block_K0 is always a multiple of block_K1 to avoid using masking, etc.\n",
    "block_N1, block_K1 = N1, block_K0 // 2\n",
    "\n",
    "# initialize B1 matrix\n",
    "B1 = torch.rand((K1, N1))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some important shapes:\n",
    "\n",
    "* shape of `A1 = matmul(A0, B0)` is `MxN0`, iterate over `K0`\n",
    "* shape of `B1` is `K1xN1` with `K1 == N0`\n",
    "* shape of `A2 = matmul(A1, B1)` is `MxN1`, iterate over `K1`\n",
    "  * because `K1 == N0`, during the second matmul we iterate over `N0`\n",
    "\n",
    "So we will set the following tile shapes:\n",
    "* `block_N0 = N0`\n",
    "* `block_N1 = N1`\n",
    "\n",
    "> In the code `block_N0` and `block_N1` instead of `:` are used for readability reasons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "accumulator2 = torch.zeros((M, N1))\n",
    "\n",
    "for index_M in range(0, M, block_M):\n",
    "    start_M = index_M\n",
    "    end_M = index_M + block_M\n",
    "    for index_K0 in range(0, K0, block_K0):\n",
    "        start_K0 = index_K0\n",
    "        end_K0 = index_K0 + block_K0\n",
    "\n",
    "        tile_A0 = A0[start_M:end_M, start_K0:end_K0]\n",
    "        tile_B0 = B0[start_K0:end_K0, :block_N0]\n",
    "        tile_A1 = tile_A0 @ tile_B0\n",
    "        for index_K1 in range(0, K1, block_K1):\n",
    "            start_K1 = index_K1\n",
    "            end_K1 = index_K1 + block_K1\n",
    "\n",
    "            tile_tile_A1 = tile_A1[:, start_K1:end_K1]\n",
    "            tile_B1 = B1[start_K1:end_K1, :block_N1]\n",
    "\n",
    "            accumulator2[start_M:end_M, :block_N1] += tile_tile_A1 @ tile_B1\n",
    "\n",
    "assert torch.allclose(accumulator2, (A0 @ B0) @ B1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}