{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T21:36:22.305096Z",
     "iopub.status.busy": "2022-10-22T21:36:22.304523Z",
     "iopub.status.idle": "2022-10-22T21:36:24.954430Z",
     "shell.execute_reply": "2022-10-22T21:36:24.952791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\r\n",
      "Requirement already satisfied: tokenizer in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (3.4.2)\r\n",
      "Requirement already satisfied: datasets in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (2.6.1)\r\n",
      "Requirement already satisfied: sentencepiece in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (0.1.97)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (1.23.4)\r\n",
      "Requirement already satisfied: xxhash in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (3.1.0)\r\n",
      "Requirement already satisfied: pandas in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (1.5.1)\r\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (2022.10.0)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (2.28.1)\r\n",
      "Requirement already satisfied: multiprocess in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.70.13)\r\n",
      "Requirement already satisfied: aiohttp in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (3.8.3)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (4.64.1)\r\n",
      "Requirement already satisfied: packaging in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (21.3)\r\n",
      "Requirement already satisfied: dill<0.3.6 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.3.5.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.10.1)\r\n",
      "Requirement already satisfied: responses<0.19 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (0.18.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (6.0)\r\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from datasets) (9.0.0)\r\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (2.1.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (1.8.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (1.2.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
      "Requirement already satisfied: filelock in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from packaging->datasets) (3.0.9)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (1.26.12)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from pandas->datasets) (2022.5)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/geantvert/.local/share/virtualenvs/kernl/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\r\n",
      "\u001B[33mWARNING: You are using pip version 21.3.1; however, version 22.3 is available.\r\n",
      "You should consider upgrading via the '/home/geantvert/.local/share/virtualenvs/kernl/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n",
      "Sat Oct 22 23:36:24 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:03:00.0  On |                  N/A |\r\n",
      "| 45%   44C    P8    40W / 350W |    320MiB / 24576MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1648      G   /usr/lib/xorg/Xorg                130MiB |\r\n",
      "|    0   N/A  N/A      7699      G   /usr/bin/gnome-shell               37MiB |\r\n",
      "|    0   N/A  N/A      8931      G   ...on/Bin/AgentConnectix.bin        4MiB |\r\n",
      "|    0   N/A  N/A   1253626      G   ...828532506883067918,131072      145MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! pip install tokenizer datasets sentencepiece\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T21:36:24.961654Z",
     "iopub.status.busy": "2022-10-22T21:36:24.960965Z",
     "iopub.status.idle": "2022-10-22T21:36:26.144108Z",
     "shell.execute_reply": "2022-10-22T21:36:26.143488Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T21:36:26.147185Z",
     "iopub.status.busy": "2022-10-22T21:36:26.146825Z",
     "iopub.status.idle": "2022-10-22T21:36:33.194808Z",
     "shell.execute_reply": "2022-10-22T21:36:33.193994Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset xnli (/home/geantvert/.cache/huggingface/datasets/xnli/fr/1.1.0/818164464f9c9fd15776ca8a00423b074344c3e929d00a2c1a84aa5a50c928bd)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b41a4cf80604fdf832529466a14e2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"BaptisteDoyen/camembert-base-xnli\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model = model.eval().cuda()\n",
    "\n",
    "model_opt = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model_opt = model_opt.eval().cuda()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "dataset = load_dataset(path=\"xnli\", name=\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Below we do a warmup, it builds the triton kernels optimized for each size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T21:36:33.211845Z",
     "iopub.status.busy": "2022-10-22T21:36:33.211340Z",
     "iopub.status.idle": "2022-10-22T21:40:09.189844Z",
     "shell.execute_reply": "2022-10-22T21:40:09.189176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216s\n"
     ]
    }
   ],
   "source": [
    "from kernl.model_optimization import optimize_model\n",
    "\n",
    "optimized_model = optimize_model(model_opt)\n",
    "start = time.time()\n",
    "shapes = [(1, w) for w in range(8, 128 + 8, 8)]\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast(enabled=True, dtype=torch.float16, cache_enabled=True):\n",
    "    for s in shapes:\n",
    "        inputs = {\n",
    "            \"input_ids\": torch.ones(s, device=\"cuda\", dtype=torch.long),\n",
    "            \"attention_mask\": torch.ones(s, device=\"cuda\", dtype=torch.long),\n",
    "        }\n",
    "        _ = optimized_model(**inputs)\n",
    "        _ = model(**inputs)\n",
    "\n",
    "print(f\"{time.time() - start:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-22T21:40:09.195034Z",
     "iopub.status.busy": "2022-10-22T21:40:09.194812Z",
     "iopub.status.idle": "2022-10-22T21:41:02.046072Z",
     "shell.execute_reply": "2022-10-22T21:41:02.045472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete_time_baseline=44.38s\n",
      "complete_time_optimized=4.95s\n",
      "nb_disagree=2\n",
      "score baseline: 0.82\n",
      "score optimize: 0.82\n"
     ]
    }
   ],
   "source": [
    "complete_time_baseline = 0\n",
    "score_baseline = 0\n",
    "complete_time_optimized = 0\n",
    "score_optimize = 0\n",
    "nb_examples = len(dataset[\"test\"])\n",
    "nb_disagree = 0\n",
    "\n",
    "with torch.inference_mode(), torch.cuda.amp.autocast(enabled=True, dtype=torch.float16, cache_enabled=True):\n",
    "    for index, content in enumerate(dataset[\"test\"]):\n",
    "        premise, hypothesis, label = content.values()\n",
    "        inputs = tokenizer(premise, hypothesis, return_tensors=\"pt\", pad_to_multiple_of=8, padding=True)\n",
    "        inputs = dict(inputs.to(\"cuda\"))\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        output_original = model(**inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        complete_time_baseline += time.time() - start\n",
    "\n",
    "        choice_baseline = torch.argmax(output_original.logits, dim=1)\n",
    "        score_baseline += label == choice_baseline.item()\n",
    "\n",
    "        start = time.time()\n",
    "        output_optimized = optimized_model(**inputs)\n",
    "        torch.cuda.synchronize()\n",
    "        complete_time_optimized += time.time() - start\n",
    "\n",
    "        choice_optimize = torch.argmax(output_optimized.logits, dim=1)\n",
    "        score_optimize += label == choice_optimize.item()\n",
    "\n",
    "        assert torch.allclose(\n",
    "            output_original.logits, output_optimized.logits, atol=1e-1\n",
    "        ), f\"logits don't match:\\n{output_original}\\n{output_optimized}\"\n",
    "        if choice_baseline != choice_optimize:\n",
    "            nb_disagree += 1\n",
    "\n",
    "print(f\"{complete_time_baseline=:.2f}s\")\n",
    "print(f\"{complete_time_optimized=:.2f}s\")\n",
    "print(f\"{nb_disagree=}\")\n",
    "print(f\"score baseline: {score_baseline / nb_examples:.2f}\")\n",
    "print(f\"score optimize: {score_optimize / nb_examples:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01370c2c3f7b4498b655dc70d0e3529c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_169b327c0d134236970370df94b75c5b",
       "placeholder": "​",
       "style": "IPY_MODEL_52f3e95b207049648a7f5440066a0d80",
       "tabbable": null,
       "tooltip": null,
       "value": " 3/3 [00:00&lt;00:00, 74.88it/s]"
      }
     },
     "0af77dd260e24ac0b3e8ec00b11fda34": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "117d7c06236242ecb176180a6f2b54fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "169b327c0d134236970370df94b75c5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3673b47b37ba4c96906b848acbb618f4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fd2dbae311644aedaee98b32407de684",
       "max": 3.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3f71f324bedd4000a453341efffb11b0",
       "tabbable": null,
       "tooltip": null,
       "value": 3.0
      }
     },
     "3f71f324bedd4000a453341efffb11b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "52f3e95b207049648a7f5440066a0d80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "8cb2ab76ad8d4bd49b53deea3cd149d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b41a4cf80604fdf832529466a14e2b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c730c10d80e24d639d6af6196a93fe5b",
        "IPY_MODEL_3673b47b37ba4c96906b848acbb618f4",
        "IPY_MODEL_01370c2c3f7b4498b655dc70d0e3529c"
       ],
       "layout": "IPY_MODEL_117d7c06236242ecb176180a6f2b54fa",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c730c10d80e24d639d6af6196a93fe5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8cb2ab76ad8d4bd49b53deea3cd149d5",
       "placeholder": "​",
       "style": "IPY_MODEL_0af77dd260e24ac0b3e8ec00b11fda34",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "fd2dbae311644aedaee98b32407de684": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
