{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chained matmul with tiling\n",
    "\n",
    "In this simple tutorial we will see how to perform a `matmul` with tiling.\n",
    "Tiling is a technique based on matrix partition, each block is called a tile.\n",
    "\n",
    "With tiling, `matmul`:\n",
    "* computation can be performed in parallel, a domain where GPUs excels;\n",
    "* global memory (GM) access are limited, GM access being the GPU bottleneck (compared to computation).\n",
    "\n",
    "From the simple example, we will expand our approach to chaining an infinite number of `matmul`.\n",
    "\n",
    "## GEMM introduction\n",
    "\n",
    "Below we define the problem size and initialize the matrices.\n",
    "In `GEMM` a problem is defined by 3 numbers: `KMN`.\n",
    "\n",
    "`D = α * A * B + β * C` with:\n",
    "* `D` shape is `MxN`\n",
    "* `A` shape is `MxK`\n",
    "* `B` shape is `KxN`\n",
    "* `C` shape is `MxN`\n",
    "* `α` and `β` are 2 constants\n",
    "\n",
    "> for readability, below `α` is implicitly set to 1 and `β` to 0 so `C` do not appear.\n",
    "> Obviously, re-introducing them would be very easy.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "M, N0, K0 = 15, 9, 12\n",
    "\n",
    "A0 = np.random.random((M, K0))\n",
    "B0 = np.random.random((K0, N0))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple matmul with tiling\n",
    "\n",
    "Simple example showing how we can perform a `matmul` through tiling.\n",
    "\n",
    "Basic introduction to the subject can be found here:\n",
    "\n",
    "* https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html\n",
    "* https://penny-xu.github.io/blog/tiled-matrix-multiplication\n",
    "\n",
    "Parallelization can be applied at each `M` and `N` for loop levels.\n",
    "However, best use of global memory access requires to be a bit smarter.\n",
    "Check our dedicated explanation in tutorials.\n",
    "\n",
    "Values used below are a arbitrary and small to be printable if needed.\n",
    "Rule of thumb in defining tile shape is:\n",
    "* large tile size increase data reuse, but decrease thread-level parallelism;\n",
    "* small tile size increase thread-level parallelism but reduce data reuse."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# for simplification tile shapes are all multiple of matrix shapes\n",
    "# otherwise we would need to check matrix bounds and mask out of bounds values by 0s in tiles\n",
    "block_M, block_N0, block_K0 = M // 3, N0 // 3, K0 // 3\n",
    "\n",
    "accumulator0 = np.zeros((M, N0))\n",
    "for index_M in range(0, M, block_M):\n",
    "    start_M = index_M\n",
    "    end_M = index_M + block_M\n",
    "\n",
    "    for index_N0 in range(0, N0, block_N0):\n",
    "        start_N0 = index_N0\n",
    "        end_N0 = index_N0 + block_N0\n",
    "\n",
    "        for index_K0 in range(0, K0, block_K0):\n",
    "            start_K0 = index_K0\n",
    "            end_K0 = index_K0 + block_K0\n",
    "\n",
    "            tile_A0 = A0[start_M:end_M, start_K0:end_K0]\n",
    "            tile_B0 = B0[start_K0:end_K0, start_N0:end_N0]\n",
    "            accumulator0[start_M:end_M, start_N0:end_N0] += np.matmul(tile_A0, tile_B0)\n",
    "\n",
    "assert np.allclose(accumulator0, np.matmul(A0, B0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Back to back fused matmul with tiling\n",
    "\n",
    "Fused matmul helps in reducing memory access as the intermediate outputs are never materialized (written in global memory).\n",
    "\n",
    "Introduction to the approach can be found here:\n",
    "https://github.com/NVIDIA/cutlass/tree/master/examples/13_two_tensor_op_fusion\n",
    "\n",
    "The main trick is to have `n` axis matrix `bx` tiles length equal to `Nx` axis `Bx` matrix length.\n",
    "Therefore, there is no need to iterate over the `N` axis.\n",
    "\n",
    "It introduces a constraint on the length of `Nx` which needs to be small enough to be kept in shared memory / registries.\n",
    "\n",
    "In the example below, we chain 2 `matmul`:\n",
    "\n",
    "* A1 = A0 * B0\n",
    "* A2 = A1 * B1\n",
    "\n",
    "> our goal is to never materialize A1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# block_Nx is always equal to Nx\n",
    "# for simplification block tile shapes are all multiple of matrices shapes\n",
    "block_M, block_N0, block_K0 = M // 3, N0, K0 // 3\n",
    "\n",
    "# by definition K1 is always N0 as A1 is multiplied with B1 and A1 N axis is the one of B0\n",
    "N1, K1 = 12, N0\n",
    "\n",
    "# we iterate over N0 so block_K0 is always a multiple of block_K1 to avoid using masking, etc.\n",
    "block_N1, block_K1 = N1, block_K0 // 2\n",
    "\n",
    "# initialize B1 matrix\n",
    "B1 = np.random.random((K1, N1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Some important shapes:\n",
    "\n",
    "* shape of `A1 = matmul(A0, B0)` is `MxN0`, iterate over `K0`\n",
    "* shape of `B1` is `K1xN1` with `K1 == N0`\n",
    "* shape of `A2 = matmul(A1, B1)` is `MxN1`, iterate over `K1`\n",
    "  * because `K1 == N0`, during the second matmul we iterate over `N0`\n",
    "\n",
    "So we will set the following tile shapes:\n",
    "* `block_N0 = N0`\n",
    "* `block_N1 = N1`\n",
    "\n",
    "> In the code `block_N0` and `block_N1` instead of `:` are used for readability reasons"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "accumulator2 = np.zeros((M, N1))\n",
    "\n",
    "for index_M in range(0, M, block_M):\n",
    "    start_M = index_M\n",
    "    end_M = index_M + block_M\n",
    "    for index_K0 in range(0, K0, block_K0):\n",
    "        start_K0 = index_K0\n",
    "        end_K0 = index_K0 + block_K0\n",
    "\n",
    "        tile_A0 = A0[start_M:end_M, start_K0:end_K0]\n",
    "        tile_B0 = B0[start_K0:end_K0, :block_N0]\n",
    "        tile_A1 = np.matmul(tile_A0, tile_B0)\n",
    "        for index_K1 in range(0, K1, block_K1):\n",
    "            start_K1 = index_K1\n",
    "            end_K1 = index_K1 + block_K1\n",
    "\n",
    "            tile_tile_A1 = tile_A1[:, start_K1:end_K1]\n",
    "            tile_B1 = B1[start_K1:end_K1, :block_N1]\n",
    "\n",
    "            accumulator2[start_M:end_M, :block_N1] += np.matmul(tile_tile_A1, tile_B1)\n",
    "\n",
    "assert np.allclose(accumulator2, np.matmul(np.matmul(A0, B0), B1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}